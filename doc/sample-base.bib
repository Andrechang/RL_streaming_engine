
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@article{Zhou_compileGNN,
  author    = {Yanqi Zhou and
               Sudip Roy and
               AmirAli Abdolrashidi and
               Daniel Wong and
               Peter C. Ma and
               Qiumin Xu and
               Hanxiao Liu and
               Mangpo Phitchaya Phothilimtha and
               Shen Wang and
               Anna Goldie and
               Azalia Mirhoseini and
               James Laudon},
  title     = {Transferable Graph Optimizers for {ML} Compilers},
  journal   = {CoRR},
  volume    = {abs/2010.12438},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.12438},
  eprinttype = {arXiv},
  eprint    = {2010.12438},
  timestamp = {Wed, 28 Oct 2020 08:28:14 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-12438.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mirhoseini2020chip,
  author    = {Azalia Mirhoseini and
               Anna Goldie and
               Mustafa Yazgan and
               Joe Jiang and
               Ebrahim M. Songhori and
               Shen Wang and
               Young{-}Joon Lee and
               Eric Johnson and
               Omkar Pathak and
               Sungmin Bae and
               Azade Nazi and
               Jiwoo Pak and
               Andy Tong and
               Kavya Srinivasa and
               William Hang and
               Emre Tuncer and
               Anand Babu and
               Quoc V. Le and
               James Laudon and
               Richard C. Ho and
               Roger Carpenter and
               Jeff Dean},
  title     = {Chip Placement with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2004.10746},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.10746},
  eprinttype = {arXiv},
  eprint    = {2004.10746},
  timestamp = {Tue, 28 Apr 2020 16:10:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-10746.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhou2019gdp,
  author    = {Yanqi Zhou and
               Sudip Roy and
               AmirAli Abdolrashidi and
               Daniel Lin{-}Kit Wong and
               Peter C. Ma and
               Qiumin Xu and
               Ming Zhong and
               Hanxiao Liu and
               Anna Goldie and
               Azalia Mirhoseini and
               James Laudon},
  title     = {{GDP:} Generalized Device Placement for Dataflow Graphs},
  journal   = {CoRR},
  volume    = {abs/1910.01578},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.01578},
  eprinttype = {arXiv},
  eprint    = {1910.01578},
  timestamp = {Wed, 16 Sep 2020 14:30:19 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-01578.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{addanki2019placeto,
  author    = {Ravichandra Addanki and
               Shaileshh Bojja Venkatakrishnan and
               Shreyan Gupta and
               Hongzi Mao and
               Mohammad Alizadeh},
  title     = {Placeto: Learning Generalizable Device Placement Algorithms for Distributed
               Machine Learning},
  journal   = {CoRR},
  volume    = {abs/1906.08879},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.08879},
  eprinttype = {arXiv},
  eprint    = {1906.08879},
  timestamp = {Mon, 24 Jun 2019 17:28:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-08879.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gori2005new,
  title={A new model for learning in graph domains},
  author={Gori, Marco and Monfardini, Gabriele and Scarselli, Franco},
  booktitle={Proceedings. 2005 IEEE international joint conference on neural networks},
  volume={2},
  number={2005},
  pages={729--734},
  year={2005}
}

@article{hochreiter1996lstm,
  title={LSTM can solve hard long time lag problems},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Advances in neural information processing systems},
  volume={9},
  year={1996}
}

@article{Zhichao_ESNAS,
  author    = {Zhichao Lu and
               Ian Whalen and
               Vishnu Boddeti and
               Yashesh D. Dhebar and
               Kalyanmoy Deb and
               Erik D. Goodman and
               Wolfgang Banzhaf},
  title     = {{NSGA-NET:} {A} Multi-Objective Genetic Algorithm for Neural Architecture
               Search},
  journal   = {CoRR},
  volume    = {abs/1810.03522},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.03522},
  eprinttype = {arXiv},
  eprint    = {1810.03522},
  timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-03522.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Shengyi_mask,
  author    = {Shengyi Huang and
               Santiago Onta{\~{n}}{\'{o}}n},
  title     = {A Closer Look at Invalid Action Masking in Policy Gradient Algorithms},
  journal   = {CoRR},
  volume    = {abs/2006.14171},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.14171},
  eprinttype = {arXiv},
  eprint    = {2006.14171},
  timestamp = {Wed, 01 Jul 2020 15:21:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-14171.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ZophL16_NASRL,
  author    = {Barret Zoph and
               Quoc V. Le},
  title     = {Neural Architecture Search with Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.01578},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01578},
  eprinttype = {arXiv},
  eprint    = {1611.01578},
  timestamp = {Mon, 13 Aug 2018 16:46:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZophL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{shi2020learned,
  author    = {Zhan Shi and
               Chirag Sakhuja and
               Milad Hashemi and
               Kevin Swersky and
               Calvin Lin},
  title     = {Learned Hardware/Software Co-Design of Neural Accelerators},
  journal   = {CoRR},
  volume    = {abs/2010.02075},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.02075},
  eprinttype = {arXiv},
  eprint    = {2010.02075},
  timestamp = {Mon, 12 Oct 2020 17:53:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-02075.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kormushev2013reinforcement,
  title={Reinforcement learning in robotics: Applications and real-world challenges},
  author={Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G},
  journal={Robotics},
  volume={2},
  number={3},
  pages={122--148},
  year={2013},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{Mirhoseini_placementRNN,
  author    = {Azalia Mirhoseini and
               Hieu Pham and
               Quoc V. Le and
               Benoit Steiner and
               Rasmus Larsen and
               Yuefeng Zhou and
               Naveen Kumar and
               Mohammad Norouzi and
               Samy Bengio and
               Jeff Dean},
  title     = {Device Placement Optimization with Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1706.04972},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.04972},
  eprinttype = {arXiv},
  eprint    = {1706.04972},
  timestamp = {Fri, 04 Jan 2019 10:57:57 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/MirhoseiniPLSLZ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{Schulman_ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  eprinttype = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{theodoridis2007survey,
  title={A survey of coarse-grain reconfigurable architectures and cad tools},
  author={Theodoridis, George and Soudris, Dimitrios and Vassiliadis, Stamatis},
  booktitle={Fine-and Coarse-Grain Reconfigurable Computing},
  pages={89--149},
  year={2007},
  publisher={Springer}
}

@article{prabhakar2018plasticine,
  title={Plasticine: a reconfigurable accelerator for parallel patterns},
  author={Prabhakar, Raghu and Zhang, Yaqi and Koeplinger, David and Feldman, Matt and Zhao, Tian and Hadjis, Stefan and Pedram, Ardavan and Kozyrakis, Christos and Olukotun, Kunle},
  journal={IEEE Micro},
  volume={38},
  number={3},
  pages={20--31},
  year={2018},
  publisher={IEEE}
}

@misc{morgan2018intel,
  title={Intel’s Exascale Dataflow Engine Drops X86 and von Neumann},
  author={Morgan, Timothy Prickett},
  year={2018}
}

@article{nicol2017coarse,
  title={A coarse grain reconfigurable array (CGRA) for statically scheduled data flow computing},
  author={Nicol, Chris},
  journal={Wave computing white paper},
  year={2017}
}

@inproceedings{vissers2019versal,
  title={Versal: The xilinx adaptive compute acceleration platform (acap)},
  author={Vissers, Kees},
  booktitle={Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  pages={83--83},
  year={2019}
}

@inproceedings{adriaansen2016code,
  title={Code generation for reconfigurable explicit datapath architectures with llvm},
  author={Adriaansen, Micha{\"e}l and Wijtvliet, Mark and Jordans, Roel and Waeijen, Luc and Corporaal, Henk},
  booktitle={2016 Euromicro Conference on Digital System Design (DSD)},
  pages={30--37},
  year={2016},
  organization={IEEE}
}

@article{mei2003exploiting,
  title={Exploiting loop-level parallelism on coarse-grained reconfigurable architectures using modulo scheduling},
  author={Mei, Bingfeng and Vernalde, Serge and Verkest, Diederik and De Man, Hugo and Lauwereins, Rudy},
  journal={IEE Proceedings-Computers and Digital Techniques},
  volume={150},
  number={5},
  pages={255},
  year={2003},
  publisher={IET}
}

@article{sharma2020compute,
  title={Compute express link 2.0 white paper},
  author={Sharma, Debendra Das and Tavallaei, Siamak},
  journal={Tech. Rep.},
  year={2020}
}

%% to cite after writeup

@article{li_chordmap_2022,
	title = {{ChordMap}: {Automated} {Mapping} of {Streaming} {Applications} {Onto} {CGRA}},
	volume = {41},
	issn = {1937-4151},
	doi = {10.1109/TCAD.2021.3058313},
	abstract = {Streaming applications, consisting of several communicating kernels, are ubiquitous in the embedded computing systems. The synchronous data flow (SDF) is commonly used to capture the complex communication patterns among the kernels. The general-purpose processors cannot meet the throughput requirement of the compute-intensive kernels in the current and emerging applications. The coarse-grained reconfigurable arrays (CGRAs) are well-suited to accelerate the individual kernel and the compiler technology is well-developed to support the mapping of a kernel onto a CGRA accelerator. However, the system-level mapping of the entire streaming application onto a resource-constrained CGRA to maximize throughput remains unexplored. We introduce a novel CGRA mapper, called ChordMap, to automatically generate a high-quality mapping of streaming applications represented as SDF onto CGRAs. We propose an optimized spatio-temporal mapping with modulo-scheduling that judiciously employs concurrent execution of multiple kernels to improve parallelism and thereby maximize throughput. ChordMap achieves, on average, \$1.74{\textbackslash}times \$ higher throughput across eight streaming applications compared to the state-of-the-art.},
	number = {2},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Li, Zhaoying and Wijerathne, Dhananjaya and Chen, Xianzhang and Pathania, Anuj and Mitra, Tulika},
	month = feb,
	year = {2022},
	pages = {306--319},
	file = {Li et al. - 2022 - ChordMap Automated Mapping of Streaming Applicati.pdf:C\:\\Users\\basharromano\\Zotero\\storage\\J49ABVM3\\Li et al. - 2022 - ChordMap Automated Mapping of Streaming Applicati.pdf:application/pdf},
}

@incollection{pathfinder,
title = {Chapter 17 - Pathfinder: A Negotiation-Based Performance-Driven Router for FPGAs},
editor = {Scott Hauck and André Dehon},
booktitle = {Reconfigurable Computing},
publisher = {Morgan Kaufmann},
address = {Burlington},
pages = {365-381},
year = {2008},
series = {Systems on Silicon},
issn = {18759661},
doi = {https://doi.org/10.1016/B978-012370522-8.50024-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123705228500248},
author = {Larry McMurchie and Carl Ebeling},
abstract = {Publisher Summary
The widespread use of PathFinder by commercial field-programmable gate array (FPGA) routers and university research efforts alike is a testimonial to its robustness. Several key facets of the algorithm make it attractive. However, its primary advantage is the iterative nature of resolving congestion, with both current as well as historical resource use in the formulation of the cost function. By very gradually increasing cost due to both usages, the routing search space is thoroughly explored. Routing with other objective functions, delay in particular, is easily integrated into the cost function. A primary feature implicit in PathFinder (that distinguishes it from previous efforts) is the allowance of non-physically feasible intermediate states—for example, shared resources—while converging to a physically feasible final state. By being grounded in a directed graph representation, PathFinder is very adaptable to changing FPGA architectures as well as other problems that can be abstracted to a directed graph. In the future the routing problem can be seen as being the increasingly dominant hurdle in the use of FPGAs with millions of resources. To reduce the runtime, more investigation will be required to effectively parallelize PathFinder, making use of additional computational resources. Given the growing focus on other objectives such as power consumption, it is likely that the experimentation with other cost function formulations will be seen as well.}
}

@article{tehre_survey_2012,
	title = {Survey on coarse grained reconfigurable architectures},
	volume = {48},
	number = {16},
	journal = {International Journal of Computer Applications},
	author = {Tehre, Vaishali and Kshirsagar, Ravindra},
	year = {2012},
	note = {Publisher: Citeseer},
	pages = {1--7},
	file = {Tehre and Kshirsagar - 2012 - Survey on coarse grained reconfigurable architectu.pdf:C\:\\Users\\basharromano\\Zotero\\storage\\UZ32P6A5\\Tehre and Kshirsagar - 2012 - Survey on coarse grained reconfigurable architectu.pdf:application/pdf},
}

@article{liu_survey_2019,
	title = {A {Survey} of {Coarse}-{Grained} {Reconfigurable} {Architecture} and {Design}: {Taxonomy}, {Challenges}, and {Applications}},
	volume = {52},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3357375},
	doi = {10.1145/3357375},
	abstract = {As general-purpose processors have hit the power wall and chip fabrication cost escalates alarmingly, coarse-grained reconfigurable architectures (CGRAs) are attracting increasing interest from both academia and industry, because they offer the performance and energy efficiency of hardware with the flexibility of software. However, CGRAs are not yet mature in terms of programmability, productivity, and adaptability. This article reviews the architecture and design of CGRAs thoroughly for the purpose of exploiting their full potential. First, a novel multidimensional taxonomy is proposed. Second, major challenges and the corresponding state-of-the-art techniques are surveyed and analyzed. Finally, the future development is discussed.},
	number = {6},
	journal = {ACM Comput. Surv.},
	author = {Liu, Leibo and Zhu, Jianfeng and Li, Zhaoshi and Lu, Yanan and Deng, Yangdong and Han, Jie and Yin, Shouyi and Wei, Shaojun},
	month = oct,
	year = {2019},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {CGRA, dataflow, reconfigurable computing, scheduling, spatial architecture},
	file = {Liu et al. - 2019 - A Survey of Coarse-Grained Reconfigurable Architec.pdf:C\:\\Users\\basharromano\\Zotero\\storage\\GYQFBCGM\\Liu et al. - 2019 - A Survey of Coarse-Grained Reconfigurable Architec.pdf:application/pdf},
}

@inproceedings{chin_cgra-me_2017,
	title = {{CGRA}-{ME}: {A} unified framework for {CGRA} modelling and exploration},
	doi = {10.1109/ASAP.2017.7995277},
	abstract = {Coarse-grained reconfigurable arrays (CGRAs) are a style of programmable logic device situated between FPGAs and custom ASICs on the spectrum of programmability, performance, power and cost. CGRAs have been proposed by both academia and industry; however, prior works have been mainly self-contained without broad architectural exploration and comparisons with competing CGRAs. We present CGRA-ME - a unified CGRA framework that encompasses generic architecture description, architecture modelling, application mapping, and physical implementation. Within this framework, we discuss our architecture description language CGRA-ADL, a generic LLVM-based simulated annealing mapper, and a standard cell flow for physical implementation. An architecture exploration case study is presented, highlighting the capabilities of CGRA-ME by exploring a variety of architectures with varying functionality, interconnect, array size, and execution contexts through the mapping of application benchmarks and the production of standard cell designs.},
	booktitle = {2017 {IEEE} 28th {International} {Conference} on {Application}-specific {Systems}, {Architectures} and {Processors} ({ASAP})},
	author = {Chin, S. Alexander and Sakamoto, Noriaki and Rui, Allan and Zhao, Jim and Kim, Jin Hee and Hara-Azumi, Yuko and Anderson, Jason},
	month = jul,
	year = {2017},
	note = {ISSN: 2160-052X},
	pages = {184--189},
	file = {Chin et al. - 2017 - CGRA-ME A unified framework for CGRA modelling an.pdf:C\:\\Users\\basharromano\\Zotero\\storage\\GE78H99W\\Chin et al. - 2017 - CGRA-ME A unified framework for CGRA modelling an.pdf:application/pdf},
}

@inproceedings{chin_architecture-agnostic_2018,
	address = {New York, NY, USA},
	series = {{DAC} '18},
	title = {An {Architecture}-{Agnostic} {Integer} {Linear} {Programming} {Approach} to {CGRA} {Mapping}},
	isbn = {978-1-4503-5700-5},
	url = {https://doi.org/10.1145/3195970.3195986},
	doi = {10.1145/3195970.3195986},
	abstract = {Coarse-grained reconfigurable architectures (CGRAs) have gained traction as a potential solution to implement accelerators for compute-intensive kernels, particularly in domains requiring hardware programmability. Architecture and CAD for CGRAs are tightly intertwined, with many prior works having combined architectures and tools. In this work, we present an architecture-agnostic integer linear programming (ILP) approach for CGRA mapping, integrated within an open-source CGRA architecture evaluation framework. The mapper accepts an application and an architecture description as input and can generate an optimal mapping, if indeed mapping is feasible. An experimental study demonstrates its effectiveness over a range of CGRA architectures.},
	booktitle = {Proceedings of the 55th {Annual} {Design} {Automation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Chin, S. Alexander and Anderson, Jason H.},
	year = {2018},
	note = {event-place: San Francisco, California},
	file = {Chin and Anderson - 2018 - An Architecture-Agnostic Integer Linear Programmin.pdf:C\:\\Users\\basharromano\\Zotero\\storage\\SB6384FP\\Chin and Anderson - 2018 - An Architecture-Agnostic Integer Linear Programmin.pdf:application/pdf},
}

@inproceedings{mrrg,
	title = {{DRESC}: a retargetable compiler for coarse-grained reconfigurable architectures},
	doi = {10.1109/FPT.2002.1188678},
	abstract = {Coarse-grained reconfigurable architectures have become increasingly important in recent years. Automatic design or compiling tools are essential to their success. In this paper, we present a retargetable compiler for a family of coarse-grained reconfigurable architectures. Several key issues are addressed. Program analysis and transformation prepare dataflow for scheduling. Architecture abstraction generates an internal graph representation from a concrete architecture description. A modulo scheduling algorithm is key to exploit parallelism and achieve high performance. The experimental results show up to 28.7 instructions per cycle (IPC) over tested kernels.},
	booktitle = {2002 {IEEE} {International} {Conference} on {Field}-{Programmable} {Technology}, 2002. ({FPT}). {Proceedings}.},
	author = {Mei, Bingfeng and Vernalde, S. and Verkest, D. and De Man, H. and Lauwereins, R.},
	month = dec,
	year = {2002},
	pages = {166--173},
	file = {Mei et al. - 2002 - DRESC a retargetable compiler for coarse-grained .pdf:C\:\\Users\\basharromano\\Zotero\\storage\\P4NV9EMI\\Mei et al. - 2002 - DRESC a retargetable compiler for coarse-grained .pdf:application/pdf},
}

@article{zhao_towards_2020,
	title = {Towards {Higher} {Performance} and {Robust} {Compilation} for {CGRA} {Modulo} {Scheduling}},
	volume = {31},
	issn = {1558-2183},
	doi = {10.1109/TPDS.2020.2989149},
	abstract = {Coarse-Grained Reconfigurable Architectures (CGRA) is a promising solution for accelerating computation intensive tasks due to its good trade-off in energy efficiency and flexibility. One of the challenging research topic is how to effectively deploy loops onto CGRAs within acceptable compilation time. Modulo scheduling (MS) has shown to be efficient on deploying loops onto CGRAs. Existing CGRA MS algorithms still suffer from the challenge of mapping loop with higher performance under acceptable compilation time, especially mapping large and irregular loops onto CGRAs with limited computational and routing resources. This is mainly due to the under utilization of the available buffer resources on CGRA, unawareness of critical mapping constraints and time consuming method of solving temporal and spatial mapping. This article focus on improving the performance and compilation robustness of the modulo scheduling mapping algorithm for CGRAs. We decomposes the CGRA MS problem into the temporal and spatial mapping problem and reorganize the processes inside these two problems. For the temporal mapping problem, we provide a comprehensive and systematic mapping flow that includes a powerful buffer allocation algorithm, and efficient interconnection \& computational constraints solving algorithms. For the spatial mapping problem, we develop a fast and stable spatial mapping algorithm with backtracking and reordering mechanism. Our MS mapping algorithm is able to map loops onto CGRA with higher performance and faster compilation time. Experiment results show that given the same compilation time budget, our mapping algorithm generates higher compilation success rate. Among the successfully compiled loops, our approach can improve 5.4 to 14.2 percent performance and takes x24 to x1099 less compilation time in average comparing with state-of-the-art CGRA mapping algorithms.},
	number = {9},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Zhao, Zhongyuan and Sheng, Weiguang and Wang, Qin and Yin, Wenzhi and Ye, Pengfei and Li, Jinchao and Mao, Zhigang},
	month = sep,
	year = {2020},
	pages = {2201--2219},
	file = {Zhao et al. - 2020 - Towards Higher Performance and Robust Compilation .pdf:C\:\\Users\\basharromano\\Zotero\\storage\\93HXV6CS\\Zhao et al. - 2020 - Towards Higher Performance and Robust Compilation .pdf:application/pdf},
}

@InProceedings{10.1007/3-540-69346-7_30,
author="Uma, R. N.
and Wein, Joel",
editor="Bixby, Robert E.
and Boyd, E. Andrew
and R{\'i}os-Mercado, Roger Z.",
title="On the Relationship Between Combinatorial and LP-Based Approaches to NP-Hard Scheduling Problems",
booktitle="Integer Programming and Combinatorial Optimization",
year="1998",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="394--408",
abstract="Enumerative approaches, such as branch-and-bound, to solv- ing optimization problems require a subroutine that produces a lower bound on the value of the optimal solution. In the domain of scheduling problems the requisite lower bound has typically been derived from either the solution to a linear-programming relaxation of the problem or the solution of a combinatorial relaxation. In this paper we investigate, from both a theoretical and practical perspective, the relationship between several linear-programming based lower bounds and combinatorial lower bounds for two scheduling problems in which the goal is to minimize the average weighted completion time of the jobs scheduled.",
isbn="978-3-540-69346-8"
}

%% RL chip


@article{khailany_accelerating_2020,
	title = {Accelerating {Chip} {Design} {With} {Machine} {Learning}},
	volume = {40},
	issn = {1937-4143},
	doi = {10.1109/MM.2020.3026231},
	abstract = {Recent advancements in machine learning provide an opportunity to transform chip design workflows. We review recent research applying techniques such as deep convolutional neural networks and graph-based neural networks in the areas of automatic design space exploration, power analysis, VLSI physical design, and analog design. We also present a future vision of an AI-assisted automated chip design workflow to aid designer productivity and automate optimization tasks.},
	number = {6},
	journal = {IEEE Micro},
	author = {Khailany, Brucek and Ren, Haoxing and Dai, Steve and Godil, Saad and Keller, Ben and Kirby, Robert and Klinefelter, Alicia and Venkatesan, Rangharajan and Zhang, Yanqing and Catanzaro, Bryan and Dally, William J.},
	month = nov,
	year = {2020},
	pages = {23--32},
	file = {Khailany et al. - 2020 - Accelerating Chip Design With Machine Learning.pdf:C\:\\Users\\basharromano\\Zotero\\storage\\EGTQHFBL\\Khailany et al. - 2020 - Accelerating Chip Design With Machine Learning.pdf:application/pdf},
}

@article{wu_core_2020,
	title = {Core {Placement} {Optimization} for {Multi}-{Chip} {Many}-{Core} {Neural} {Network} {Systems} with {Reinforcement} {Learning}},
	volume = {26},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3418498},
	doi = {10.1145/3418498},
	abstract = {Multi-chip many-core neural network systems are capable of providing high parallelism benefited from decentralized execution, and they can be scaled to very large systems with reasonable fabrication costs. As multi-chip many-core systems scale up, communication latency related effects will take a more important portion in the system performance. While previous work mainly focuses on the core placement within a single chip, there are two principal issues still unresolved: the communication-related problems caused by the non-uniform, hierarchical on/off-chip communication capability in multi-chip systems, and the scalability of these heuristic-based approaches in a factorially growing search space. To this end, we propose a reinforcement-learning-based method to automatically optimize core placement through deep deterministic policy gradient, taking into account information of the environment by performing a series of trials (i.e., placements) and using convolutional neural networks to extract spatial features of different placements. Experimental results indicate that compared with a naive sequential placement, the proposed method achieves 1.99× increase in throughput and 50.5\% reduction in latency; compared with the simulated annealing, an effective technique to approximate the global optima in an extremely large search space, our method improves the throughput by 1.22× and reduces the latency by 18.6\%. We further demonstrate that our proposed method is capable to find optimal placements taking advantages of different communication properties caused by different system configurations, and work in a topology-agnostic manner.},
	number = {2},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Wu, Nan and Deng, Lei and Li, Guoqi and Xie, Yuan},
	month = oct,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {core placement optimization, machine learning for system, Multi-chip many-core architecture, neural network accelerator},
	file = {Wu et al. - 2020 - Core Placement Optimization for Multi-Chip Many-Co.pdf:C\:\\Users\\basharromano\\Zotero\\storage\\HEUUNYXR\\Wu et al. - 2020 - Core Placement Optimization for Multi-Chip Many-Co.pdf:application/pdf},
}