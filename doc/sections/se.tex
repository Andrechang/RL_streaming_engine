The SE is a coarse-grained fabric composed of compute tiles, which are interconnected with an SF, allowing data to traverse from one tile to another without queuing.
This SF allows many tiles to be pipelined together to produce a continuous data flow through SIMD arithmetic operations.
The tiles are also interconnected with an AF that allows synchronous domains of compute to be bridged by asynchronous operations.
These asynchronous operations include initiating synchronous domain operations, transferring data from one synchronous domain to another, accessing system memory (read and write), and performing branching and looping constructs.
Together, the SF nad AF allow the tiles to efficiently execute high level language constructs.

\begin{figure}
  \centering
  \includegraphics[trim=10 100 8 50, clip, width=\linewidth]{fig/se_device_tile.pdf}
  \caption{
    Diagram of the Streaming Engine to the right and diagram of a tile to the left.
    In the SE device diagram to the left, the solid black lines connecting the tiles, represent an SF connection with one clock cycle latency.
    The dotted black lines connecting the tiles, represent an SF connection with two clock cycles latency.
    The orange solid lines represent AF connections to the four MIs and the DI.
    The green solid lines represent connections to the Network-On-Chip (NOC) interfaces.
    The MIs and DI communicate with memory and the Command Manager using these NOC interfaces.
    In the Tile diagram to the right, SF Out Up1 and SF Out Down1 represent outputs from the tile to the tiles are one-hop above and below the tile respectively.
    SF Out U2 and SF Out Down2 represent outputs from the tile to the tiles are two-hops above and below the tile respectively.
    SF In Up1 and SF In Down1 represent inputs from the tile to the tiles are one-hop above and below the tile respectively.
    SF In U2 and SF In Down2 represent inputs from the tile to the tiles are two-hops above and below the tile respectively.
  }
  \label{fig:se_diagram}
\end{figure}

As shown in the Fig. \ref{fig:se_diagram}, tiles are interconnected in a one by sixteen configuration.
The SF is used to connect a tile to another tile one hop above it, a tile two hops above it, a tile one hop below it and a tile two hops below it.
Information is transferred over the SF with a deterministic latency. 
Each tile acts independently, streaming data through internal memory and MS/AL units, to other tiles over the SF and AF.
The tiles use the AF to communicate between synchronous domains, send load and stores to memory through the MI, and receive commands from the host through the DI to initiate work on the SE.
Information is transferred over the AF with a non-deterministic latency.


\subsection{Synchronous Fabric Interface}
All tiles that participate in a synchronous domain act as a single pipelined data path.
The Base Tile (BT) is define as the first tile of a synchronous domain initiates a thread of work through the pipelined tiles.
The BT is responsible for starting work on a predefined cadence referred to as the Spoke Count or Initiation Interval (II).
E.g. if $II = 3$ as in the example in Fig. \ref{fig:se_example}, then the BT can initiate work every third clock.
The synchronous fabric provides both data and control information.

\subsection{Asynchronous Fabric interface}
The Asynchronous Fabric is used to perform operations that occur asynchronous to a synchronous domain.
Each tile contains an interface to the Asynchronous Fabric.
Asynchronous Fabric messages can be classified as either data messages or control.
Data messages contain a SIMD width data value that is written to one of the two tile memories.
Control messages are for controlling thread creation, freeing resources, or issuing external memory requests.

\subsection{Tile Base}
The tile base contains data structures that are used to initiate a synchronous flow.
%It receives messages from the SF interface to configure state and set up the necessary conditions to start a synchronous flow.
%It initiates a flow into the SF when the required conditions are met.
%It also contains control logic to manage iterations of loops.
A new thread is launched by the tile base of the BT every II.
The II allows the base logic to launch new threads or continue previously launched threads when all resources needed for execution are available.

\subsection{Tile Memory}
Each tile contains two memories, each are the width of the data path (512-bits), and the depth will be in the range of 512 to 1024 elements.
The tile memories are used to store data required to support data path operations.
The stored data can be constants loaded as part of the program's arguments, or variables calculated as part of the data flow.
The tile memory can be written from the AF as either a data transfer from another synchronous domain, or the result of a load operation
initiated by another synchronous domain.
%The tile memory is only read via synchronous data path instruction execution.

\subsection{Instructions RAM}
Each tile has an instruction RAM has multiple entries to allow a tile to be time sliced, performing multiple, different operations in a pipelined synchronous domain.
%Additionally, each time slice could conditionally perform different instructions depending on previous tile time slice data dependent conditional operations. 

\subsection{Spoke RAM}
The Spoke RAM entries are used to configure the tile at each time slice.
The number of active entries spoke RAM in a tile is equal to the II of that tile.
Some of the relevant configurations per an entry are: 

\begin{itemize}
  \item Which of the four SF inputs, feedback from the output of the tile's MS/AL unit, or the tile base is the master input.
  \item Which of the four SF outputs is used to send the output of the MS/AL unit to another tile using SF.
\end{itemize}

The Spoke RAM iterates over its entries comes using a counter that modulo counts from zero to II minus one and back to zero.
%Using different spoke counts on different tiles can be a powerful mechanism that allows the number of slices required by an inner loop to determine the performance of an application.
The proposed RL mapper provides the II and the configuration of each spoke RAM entry for each tile, as well as which entry from the instruction RAM can be active on that spoke entry.


A program is broken down into a set of one or more synchronous data-flows.
A synchronous data-flows is represented as a computation graph, where every instruction a node.
Each node represents an instruction that needs to be placed onto a SE tile at he proper time-slice such that when all nodes are placed, the program executes correctly. 
In Fig. \ref{fig:se_example}, the edges of the graph represent the data dependencies of the instructions. 
The nodes also contain information about the variables that need to be present in tile memories during instruction execution. 
The instruction intended to execute at a specific time-slice will only execute when the master input configured in the corresponding Spoke RAM entry receives a valid control message.
%The tiles can pass data to their neighbors and each tile can be configured with a different number of initiation intervals (II). 
%Each II can be allocated to run a single instruction during program execution. 
%After one cycle, the tiles will move on to the next II, with execution returning to first II after the last. 
%All tiles run the instruction in the same II in parallel. 
%Thus, whenever possible, independent instructions should be mapped to different tiles and same II to exploit parallelism. 
%The first operation of each disconnected component of the computation graph (one component representing a synchronous flow) needs to be placed on different tiles. 

\subsection{SE Mapping Constraints}
The SE hardware imposes constraints that the RL mapper must adhere to in order to for it to produce a valid mapping. These constraints are:
\begin{enumerate}
  \item Instructions that share one or more tile memory variables must be placed on the same tile.
  \item No two or more instructions that start a synchronous data-flow can share a tile.
  \item No two or more instructions that are siblings can share a tile.
\end{enumerate}
The SE device configuration and its constraints are modeled in a simulation environment and the reward function.
In order to enforce these constraints, we explore two methods: the first method is to give a negative reward when a 
constraint is violated and the second is creation of a mask on the invalid actions so that the network only outputs valid actions.
In both cases, placing instructions sub-optimally leads to a reduced reward whereas placements that optimally reduce total execution time of the graph are rewarded. 